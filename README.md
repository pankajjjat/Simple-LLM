# ğŸ¤– Simple LLM Install

**Simple LLM Install** is a Python-based tool that helps you easily run and chat with **local Large Language Models (LLMs)** using **Ollama**.
No cloud, no API keys â€” everything runs locally on your machine.

---

## ğŸš€ Features

- âœ… Check if Ollama is installed
- âœ… Automatically detect if Ollama service is running
- ğŸ“¥ Download LLM models from Ollama
- ğŸ“‹ List available local models
- ğŸ’¬ Simple interactive chat interface
- ğŸ”’ Fully local & privacy-friendly

---

## ğŸ›  Prerequisites

### 1ï¸âƒ£ Python 3.8+
```bash
python --version
```

### 2ï¸âƒ£ Ollama Installed
Download from: https://ollama.ai/

**Install commands**
- **Windows**: Use the installer from the website
- **macOS**:
```bash
brew install ollama
```
- **Linux**:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

---

## â–¶ï¸ Getting Started

### Clone the repository
```bash
git clone https://github.com/pankajjjat/simple-llm-install.git
cd simple-llm-install
```

### Install dependencies
```bash
pip install requests
```

### Start Ollama
```bash
ollama serve
```

### Run the app
```bash
python main.py
```

---

## ğŸ“¦ Popular Models

| Model | Use Case | Approx Size |
|------|---------|-------------|
| llama2 | General chat | ~3.8GB |
| mistral | Fast & efficient | ~4.1GB |
| codellama | Coding assistant | ~3.8GB |
| llama2:13b | Advanced reasoning | ~7.3GB |

Download example:
```bash
ollama pull llama2
```

---

## ğŸ’¬ Chat Commands

- `quit` â†’ Exit chat
- `models` â†’ Show available models

---

## ğŸ“ Project Structure

```text
simple-llm-install/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
```

---

## ğŸ” Privacy

- 100% local execution
- No API keys
- No data tracking

---

## ğŸ“„ License

Licensed under the **MIT License**.

---

## â­ Support

If you like this project, give it a â­ on GitHub!
